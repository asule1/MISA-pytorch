{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_armpl_info:\n",
      "  NOT AVAILABLE\n",
      "blas_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/data/users3/asule/envs/pt2/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/data/users3/asule/envs/pt2/include']\n",
      "blas_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/data/users3/asule/envs/pt2/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/data/users3/asule/envs/pt2/include']\n",
      "lapack_armpl_info:\n",
      "  NOT AVAILABLE\n",
      "lapack_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/data/users3/asule/envs/pt2/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/data/users3/asule/envs/pt2/include']\n",
      "lapack_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/data/users3/asule/envs/pt2/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/data/users3/asule/envs/pt2/include']\n",
      "Supported SIMD extensions in this NumPy install:\n",
      "    baseline = SSE,SSE2,SSE3\n",
      "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2,AVX512F,AVX512CD,AVX512_SKX,AVX512_CLX\n",
      "    not found = AVX512_KNL,AVX512_KNM,AVX512_CNL,AVX512_ICL\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import fnmatch\n",
    "import natsort\n",
    "from re import search\n",
    "import pandas as pd\n",
    "\n",
    "filepath = '/data/users2/dkhosravinezhad1/MISA-pytorch/run'\n",
    "loss_filepath = '/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log'\n",
    "array_number = len(os.listdir(filepath)[2:])\n",
    "slurm_length = int(len(os.listdir(loss_filepath))/2)\n",
    "slurm_filename = []\n",
    "for i in os.listdir(loss_filepath):\n",
    "  if fnmatch.fnmatch(i, 'output*'):\n",
    "    slurm_filename.append(i)\n",
    "slurm_filename = natsort.natsorted(slurm_filename)\n",
    "slurm_final_loss = [-1]\n",
    "filename = 'res_sim-siva.p'# input(\"Insert file directory here: \")\n",
    "loss = []\n",
    "seventy_fifth_loss = []\n",
    "filetype = filename[-2:]\n",
    "lr = []\n",
    "epochs = []\n",
    "batch_size = []\n",
    "epoch = []\n",
    "h = 0\n",
    "ind = 0\n",
    "def SLURM():\n",
    "  global ind\n",
    "  slurm_b = slurm_filename[ind].split('-')[1]\n",
    "  slurm_c = slurm_b.split('.')[0]\n",
    "  with open(slurm_full, 'r') as lost:\n",
    "    loss_line = lost.readlines()[-2]\n",
    "    print(\"array \" + slurm_c + \" final loss: \" + loss_line[-27:-19])\n",
    "    loss.append(loss_line[-27:-19])\n",
    "    lost.seek(0)\n",
    "    seventy = len(lost.readlines())\n",
    "  if seventy >= 78:\n",
    "    with open(slurm_full, 'r') as lost:\n",
    "      seven_five = lost.readlines()[78]\n",
    "      print(\"array \" + slurm_c + \" 75th loss: \" + seven_five[-27:-19])\n",
    "      seventy_fifth_loss.append(seven_five[-27:-19])\n",
    "      lost.seek(0)\n",
    "  else:\n",
    "    print(slurm_full + \" does not contain a 75th epoch\")\n",
    "    seventy_fifth_loss.append(None)\n",
    "  with open(slurm_full, 'r') as lost:\n",
    "    epoch_iterations = lost.readlines()[4:-1]\n",
    "    epoch_list = []\n",
    "    for i in epoch_iterations:\n",
    "        epoch_list.append(i[-27:-19])\n",
    "    for i, l in enumerate(epoch_list):\n",
    "      if search('170', l[:-5]):\n",
    "        epoch.append(i+1)\n",
    "        print(\"array \" + slurm_c + \" MATLAB loss epoch: \" + str(i+1))\n",
    "        break\n",
    "      elif search('169', l[:-5]):\n",
    "        epoch.append(i+1)\n",
    "        print(\"array \" + slurm_c + \" MATLAB loss epoch: \" + str(i+1))\n",
    "        break\n",
    "    else:\n",
    "      epoch.append(400)\n",
    "      print(\"array \" + slurm_c + \" MATLAB loss epoch: 400\")\n",
    "    ind += 1\n",
    "    # a=\"xxxxx-<index>.out\" # slurm filename\n",
    "# b=a.split('-')[1] # here you get \"<index>.out\"\n",
    "# c=b.split('.')[0] # here you get \"<index>\"\n",
    "for i in range(slurm_length):\n",
    "  slurm_full = os.path.join(loss_filepath,slurm_filename[i])\n",
    "  output_exists = exists(slurm_full)\n",
    "  if os.stat(slurm_full).st_size != 0:\n",
    "    SLURM()\n",
    "  else:\n",
    "    print(slurm_full + \" has no contents. Check error file for problem!\")\n",
    "\n",
    "for i in range(array_number):\n",
    "  full_filename = os.path.join(filepath,str(i), filename)\n",
    "  file_exists = exists(full_filename)\n",
    "  if file_exists:\n",
    "    if i < 10:\n",
    "      j = full_filename[-16]\n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[int(j)]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[int(j)]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[int(j)]))\n",
    "    elif i > 99:\n",
    "      j = int(full_filename[-18:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "    else:\n",
    "      j = int(full_filename[-17:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "  elif filetype == \"pt\":\n",
    "    print(torch.load(full_filename,map_location=torch.device('cpu')))\n",
    "  else:\n",
    "    print(full_filename + \" does not exist or is corrupted.\")\n",
    "    h += 1\n",
    "print(\"learning rate list:\" + str(lr)) \n",
    "print(\"epochs list: \" + str(epochs)) \n",
    "print(\"batch size list: \" + str(batch_size))\n",
    "print(\"final loss list: \" + str(loss))\n",
    "print('75th loss list: ' + str(seventy_fifth_loss))\n",
    "print('MATLAB loss epoch list: ' + str(epoch))\n",
    "print(\"learning rate list length: \" + str(len(lr))) \n",
    "print(\"epochs list length: \" + str(len(epochs))) \n",
    "print(\"batch size list length: \" + str(len(batch_size)))\n",
    "print(\"final loss list length: \" + str(len(loss)))\n",
    "print(\"75th loss list length: \" + str(len(seventy_fifth_loss)))\n",
    "print('MATLAB loss epoch list length: ' + str(len(epoch)))\n",
    "\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, loss, seventy_fifth_loss, epoch)),\n",
    "               columns =['learning rate', 'epochs', 'batch size','final loss','75th loss', 'MATLAB loss epoch'])\n",
    "df.to_csv('/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_csv/SLURM.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# MATLAB_loss_epoch= [31,7,43,6,397,2,400,73,79,None,53,14,3,10,9,8,8,14,6,10,7,11,9,31,6,7,71,7,13,109,34,39,400,17,None,400,51,6,11,400,6,425,31,154,4,15,400,None,169,2,10,27,9,15,67,102,6,12,27,11,23,19,5,4,6,8,18,39,44,400,53,4,8,94,400,400,34,33,400,11,400,27,46,39,8,8,35,47,400,16,53,21,400,35,40,15,91,400,102,26,22,85,28,36]\n",
    "# end_loss = [170.625,169.2216,169.881,172.6425,171.5856,171.4906,200.8244,171.4209,168.0032,None,170.4624,170.3961,168.8855,169.0507,169.3977,170.8383,169.5728,170.1414,170.4737,169.2979,170.8414,168.4813,170.9302,177.1033,170.127,175.239,172.0257,172.6612,170.4685,170.6348,173.9354,170.0953,182.8782,171.4582,None,174.7932,170.7267,169.7895,170.9821,177.5318,170.8467,170.7996,169.0987,172.5514,172.9049,168.9981,174.8774,None,171.8029,169.0201,170.1617,171.0394,164.014,170.8149,170.3139,169.9398,172.1823,170.3637,172.2119,172.2723,163.2362,171.8841,168.7147,170.7006,170.7408,171.6105,170.6718,171.2721,170.8758,173.928,174.0465,170.6715,169.985,170.9204,190.0418,179.1302,171.0091,172.7695,191.3036,169.4706,179.7738,172.5031,174.2779,172.9253,168.5179,170.9191,171.3534,168.7726,182.7285,171.5121,169.7371,171.7798,176.1571,175.0971,169.9502,169.1821,169.373,198.2109,170.2366,168.2848,168.9214,171.7177,170.0708,168.91]\n",
    "# MATLAB_loss_epoch = np.log10(np.array(MATLAB_loss_epoch,dtype=np.float32))\n",
    "# print(MATLAB_loss_epoch)\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, loss, epoch)),\n",
    "               columns =['learning rate', 'epochs', 'batch size','final loss','MATLAB loss epoch'])\n",
    "\n",
    "fig = px.parallel_coordinates(df, color=\"MATLAB loss epoch\",\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                             color_continuous_midpoint=185)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, loss, epoch)),\n",
    "               columns =['learning rate', 'epochs', 'batch size','final loss','MATLAB loss epoch'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a6bedd3509665544335308e415059c0a09ae1dacea269d4d09537be5f92701a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
